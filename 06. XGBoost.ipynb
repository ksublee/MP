{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2baf930",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "최적화된 그레디언트 부스팅 구현으로 XGBoost라는 것이 유명하다.\n",
    "\n",
    "XGBoost는 eXtreme Gradient Boosting의 약자로서, 확장성 때문에 구조화된 데이터에 대한 응용 머신 러닝에서 많이 활용된다.\n",
    "\n",
    "XGBoost는 gradient boost를 개선한 방법이라고 볼 수 있으며, 속도와 성능을 향상시키도록 특별히 설계되었다.\n",
    "\n",
    "XGBoost에서 최적화를 위한 목적 함수의 두드러진 특징은 훈련 손실과 규제항의 두 부분으로 구성된다는 것이다.\n",
    "\n",
    "Regularized learning을 통해 과적합을 피하고, 단순하고 예측가능한 모형을 선택할 수 있게 한다. \n",
    "\n",
    "$$ \\text{obj}(\\theta) = L(\\theta) + \\Omega(\\theta) $$\n",
    "\n",
    "Tree 방법에서 정규화항은 일종의 모델 복잡도 (complexity of the tree)로 정의된다.\n",
    "\n",
    "그 외에 병렬화와 시스템 최적화로 기존의 gradient boosting에 비해 성능이 높다고 알려져 있다.\n",
    "\n",
    "아래는 [XGBoost](https://xgboost.readthedocs.io/en/stable/tutorials/model.html) 패키지의 메뉴얼의 내용을 요약한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603138c",
   "metadata": {},
   "source": [
    "### Tree\n",
    "\n",
    "XGBoost는 CART(Classification And Regression Tree)들이 모인 일종의 앙상블 모형이다.\n",
    "\n",
    "일반적인 gradient boosting과 동일한 방법으로부터 출발한다.\n",
    "\n",
    "즉, boosting의 각 step에서 작은 트리 (weak learner)들을 적합한다.\n",
    "\n",
    "학습된 트리는 이전 단계까지 학습된 모형에 합하는 additive 방식을 취한다.\n",
    "\n",
    "XGBoost에서는 CART를 형성할 때 마지막 leaf 노드에서 일종의 숫자로 이루어진 score를 배정한다. \n",
    "\n",
    "예를 들어 A와 B 클래스가 있을 때, score는 높을수록 A 클래스에 속할 확률이 높고, score가 낮을수록 B 클래스에 속할 확률이 높아질 수 있도록 설계할 수 있을 것이다.\n",
    "\n",
    "이 score는 일종의 모형 모수로서, 최적화의 대상이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c15e64",
   "metadata": {},
   "source": [
    "### 규제항\n",
    "\n",
    "XGBoost는 모델 복잡도를 낮추기 위해 규제항을 사용한다. \n",
    "\n",
    "어떤 트리 (weak learner) $f$에 대한 규제항은 다음과 같이 정의된다.\n",
    "\n",
    "$$ \\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2 $$\n",
    "\n",
    "여기서 $T$는 $f$의 leaf node의 수이고, $w_j$는 각 leaf node의 score이다.\n",
    "\n",
    "$\\gamma$와 $\\lambda$는 hyperparameter이다.\n",
    "\n",
    "즉, leaf 노드의 숫자가 많을수록, 그리고 leaf node의 score들의 제곱이 클 수록 더 큰 페널티를 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b62302",
   "metadata": {},
   "source": [
    "### 2차 근사\n",
    "\n",
    "XGBoost가 빠른 이유 중 하나는 최적화 단계에서 2차 근사를 사용하기 때문이다.\n",
    "\n",
    "트리를 이용한 부스팅에서 step $t$까지 진행되었을 때 step $t$에서의 예측값은 다음으로 표현할 수 있다.\n",
    "\n",
    "$$ \\hat y^{(t)}_i = \\sum_{k=1}^{t} f_k(x_i) = \\hat y_{i}^{(t-1)} + f_t(x_i) $$\n",
    "\n",
    "여기서 $f_t$는 step $t$에서 추가되는 트리이다.\n",
    "\n",
    "XGBoost에서 어떤 loss function $\\ell$에 대해 step $t$에서의 최적화의 대상이 되는 목적함수는 다음과 같이 표현된다.\n",
    "\n",
    "$$ \\mathrm{obj}^{(t)} = \\sum_{i=1}^{n} \\ell(y_i, \\hat y_{i}^{(t)} ) + \\Omega = \\sum_{i=1}^{n} \\ell(y_i,\\hat y_{i}^{(t-1)} + f_t(x_i) ) + \\Omega $$\n",
    "\n",
    "Loss function의 두번째 인자에 대해 $\\hat y_{i}^{(t-1)}$에서 Taylor 2차 근사를 하면\n",
    "$$ \\mathrm{obj}^{(t)} \\approx  \\sum_{i=1}^{n} \\left[ \\ell(y_i,\\hat y_{i}^{(t-1)}) + g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i) \\right]  + \\Omega $$\n",
    "\n",
    "로 표현할 수 있으며, 여기서 $g_i$와 $h_i$는 각각 $\\ell(y_i, \\hat y_{i}^{(t-1)})$의 두번째 인자에 대한 1차와 2차 미분을 $\\hat y_{i}^{(t-1)}$에서 계산한 값이다:\n",
    "\n",
    "$$ g_i = \\left. \\frac{\\partial \\ell(y_i, \\hat y)}{\\partial \\hat y} \\right|_{ \\hat y = \\hat y_{i}^{(t-1)}} \\quad  \\left. h_i = \\frac{\\partial^2 \\ell(y_i, \\hat y)}{\\partial \\hat y^2} \\right|_{ \\hat y = \\hat y_{i}^{(t-1)}} $$\n",
    "\n",
    "XGBoost 또한 일반적인 gradient boosting에서처럼 각 boosting step에서 새롭게 추가되는 트리 $f_t$에 대해서만 최적화를 진행하는 additive model이다.\n",
    "\n",
    "* 모든 가능한 트리에 대해 최적화를 진행하는 것은 어렵기 때문\n",
    "\n",
    "따라서 최적화를 step $t$에서만 추가되는 트리에 대해서만 진행한다면 목적함수에서 $\\ell(y_i,\\hat y_{i}^{(t-1)})$를 생략하고\n",
    "\n",
    "$$ \\mathrm{obj}^{(t)} \\approx  \\sum_{i=1}^{n} \\left[ g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i) \\right]  + \\Omega $$\n",
    "\n",
    "로 표현할 수 있다.\n",
    "\n",
    "여기서 $g_i$와 $h_i$는 $t-1$ 단계까지의 계산된 값으로 산출되는 값들임을 살펴보라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0d3e1",
   "metadata": {},
   "source": [
    "### Structure score\n",
    "\n",
    "위 obj 함수는 규제항을 대입하여 다음과 같이 다시 표현할 수 있다.\n",
    "\n",
    "$$ \\mathrm{obj}^{(t)} \\approx  \\sum_{i=1}^{n} \\left[ g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i) \\right] +  \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2 $$\n",
    "\n",
    "한편, 트리를 $f_t(x_i) = w_{q(x_i)}$로 표현할 수 있는데, 여기서 $q(x_i)$는 $x_i$가 최종적으로 도착할 leaf의 index로 mapping하는 함수이다.\n",
    "\n",
    "그러면,\n",
    "\n",
    "$$ \\mathrm{obj}^{(t)} \\approx  \\sum_{i=1}^{n} \\left[ g_i w_{q(x_i)} + \\frac{1}{2} h_i w^2_{q(x_i)} \\right] +  \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2 $$\n",
    "\n",
    "이며, 동일 leaf에서는 동일한 score를 가진다는 점을 이용하면,\n",
    "\n",
    "$$ \\mathrm{obj}^{(t)} \\approx \\sum_{j=1}^{T} \\left[ \\left(\\sum_{i \\in I_j} g_i \\right)w_j + \\frac{1}{2} \\left(\\sum_{i \\in I_j} h_j + \\lambda \\right) w_j^2 \\right] + \\gamma T $$\n",
    "\n",
    "이다. 여기서 $I_j$는 $j$번째 leaf node에 최종적으로 도착하는 $i$들의 집합이다.\n",
    "\n",
    "간단히 하기 위해 $G_j = \\sum_{i\\in I_j} g_i $, $H_j = \\sum_{i\\in I_j} h_i $라고 하면,\n",
    "\n",
    "$$ \\mathrm{obj}^{(t)} \\approx \\sum_{j=1}^{T} \\left[G_j w_j + \\frac{1}{2} (H_j + \\lambda) w_j^2 \\right] + \\gamma T $$\n",
    "\n",
    "이며, $w_j$에 대한 이차식이다.\n",
    "\n",
    "Leaf node의 스코어를 의미하는 $w_j$들은 서로 독립적이기 때문에, 각 $j$별로 optimal point를 구할 수 있다.\n",
    "\n",
    "위 식을 $w_j$에 대해 미분하였을 때 \n",
    "\n",
    "$$\\frac{\\partial \\mathrm{obj}^{(t)}}{\\partial w_j} = 0$$\n",
    "\n",
    "이 성립하는 위치를 찾으면, 이는\n",
    "\n",
    "$$ w_j^* = -\\frac{G_j}{H_j + \\lambda} $$\n",
    "\n",
    "이고, 이를 다시 obj 함수에 대입하면,\n",
    "\n",
    "$$ \\mathrm{obj}^* = - \\frac{1}{2} \\sum_{j=1}^{T} \\frac{G_j^2}{ H_j + \\lambda} + \\gamma T $$\n",
    "\n",
    "이다. 위 식의 값을 tree structure score라고 부르자.\n",
    "\n",
    "$H_j$와 $G_j$는 트리의 각 leaf node $j$에서 $t-1$ 단계의 값들인 $\\hat y^{(t-1)}$들과 loss function을 이용해서 계산되는 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce6ad1-f779-4654-9411-7cedb9b6a703",
   "metadata": {},
   "source": [
    "### 실제 학습 과정\n",
    "\n",
    "각 부스팅 단계에서 최적의 트리를 찾아 보자.\n",
    "\n",
    "이를 위해서는 위에서 설명한 tree structure score를 모든 가능한 트리마다 계산해 보아야 한다.\n",
    "\n",
    "모든 가능한 weak learner들, 즉, 모든 가능한 feature variable들과 분할 기준에 대해 tree structure score를 계산해 본 후,\n",
    "\n",
    "가장 작은 tree structure score를 가지는 트리를 선택하면 된다.\n",
    "\n",
    "하지만 이는 계산상으로 쉽지 않아 기본적인 결정트리에서의 훈련처럼 일종의 greedy algorithm을 적용한다.\n",
    "\n",
    "먼저 root로부터 트리의 가지를 한 번 분할하면서, 분할할 때 tree structure score를 최대한 작게 만드는 변수와 분할 지점을 찾는다.\n",
    "\n",
    "이 때, 트리를 분할할 때 생기는 새로운 leaf node들을 각각 $L$과 $R$이라고 한다면, 이 분할을 통해 얻어지는 추가적인 score gain인\n",
    "\n",
    "$$ \\frac{1}{2} \\left[ \\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L + G_R)^2}{H_L + H_R + \\lambda} \\right] - \\gamma$$\n",
    "\n",
    "를 고려한다. (위에서의 $\\mathrm{obj}^*$를 이용해 유도한 식.)\n",
    "\n",
    "$G_L$과 $H_L$, 그리고 $G_R$과 $H_R$은 새롭게 분할된 두 leaf에서 계산되는 값들이다.\n",
    "\n",
    "위 식은 트리를 추가적으로 분할할 때 (분할하지 않았을 때에 비해), score 상으로 이득을 얻는지 손해를 보는지 계산하며, 만약 이 값이 0보다 작으면 더이상 트리를 분할하지 않는다.\n",
    "\n",
    "만약 트리가 분할된다면, 이 과정을 weak learner의 미리 설정해 놓은 max depth에 이르기까지 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c81a3-e3e5-43ce-bb49-1fb144ba5294",
   "metadata": {},
   "source": [
    "### 요약\n",
    "\n",
    "1. 초기 모형 $f_0$은 손실 함수를 최소화하는 상수로 설정, 예를 들어 회귀 문제와 제곱손실함수의 경우 평균값 이용 <br><br>\n",
    "\n",
    "2. $t = 1, \\cdots, T$에 대해 다음을 반복 <br><br>\n",
    "\n",
    "    1. root로부터 시작하여 tree structure score를 최소화하는 변수와 분할 지점 계산 <br><br>\n",
    "    \n",
    "    2. Weak learner $f_t$의 max depth에 도달하거나 score gain이 0보다 큰 동안 지속적으로 분할 시도 (tree structure score를 최소화하는 변수와 분할 지점을 계산) <br><br>\n",
    "    \n",
    "    3. Weak learner $f_t$ 훈련되면 이전까지 훈련된 모형에 $\\eta$의 학습률로 합산 : $f = f_0 +\\eta \\sum_{j=1}^t f_j $, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a2798-3f5c-4ea5-ae10-b3c0826a4190",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [XGBoost](https://xgboost.readthedocs.io/en/stable/index.html) \n",
    "\n",
    "XGBoost를 구현한 라이브러리로서 python외에도 다양한 언어가 지원된다.\n",
    "\n",
    "XGBoost 자체는 scikit-learn과는 별도의 라이브러리이지만, XGBoost는 scikit-learn의 인터페이스를 따르는 래퍼 (Wrapper) 클래스를 제공한다.\n",
    " \n",
    "이를 통해, Scikit-learn과 일관된 API를 이용할 수 있다.\n",
    "\n",
    "XGBoost의 scikit-learn 래퍼를 사용하려면 xgboost 패키지를 설치한 후, `xgboost.XGBRegressor` 또는 `xgboost.XGBClassifier`와 같은 클래스를 import하여 사용할 수 있다.\n",
    "\n",
    "이러한 클래스는 scikit-learn의 `fit`, `predict` 등과 같은 메서드를 제공하여 모델을 학습하고 예측할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206a7f7",
   "metadata": {},
   "source": [
    "### 예제 : Iris 데이터\n",
    "\n",
    "[`xgboost.XGBClassifier`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier)를 이용하여 먼저 간단한 분류 모형을 연습해 보자.\n",
    "\n",
    "기본적으로 XGBoost의 분류는 binary 분류를 기반으로 하기 때문에, 0과 1의 두 클래스가 있는 경우를 먼저 살펴본다.\n",
    "\n",
    "Iris data의 y값은 3개의 클래스이나, 간단히 versicolor인지 아닌지 체크하는 문제를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a14f2ecd-f8c2-4413-9c6d-e1e599e9c456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "599c7101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=.2)\n",
    "\n",
    "# versicolor or not\n",
    "y_train[y_train != 1] = 0\n",
    "y_test[y_test != 1] = 0\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3250d-1af4-43aa-9069-9cfefa5d651e",
   "metadata": {},
   "source": [
    "연습을 위해 [`XGBClassifier`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier)를 이용한 매우 간단한 모형을 살펴보자.\n",
    "\n",
    "Weak learner는 최대 깊이 1의 stump이다.\n",
    "\n",
    "Boosting의 단계 수는 2으로 하였다. (보통은 훨씬 많은 단계를 사용한다.)\n",
    "\n",
    "scikit-learn의 문법과 흡사하게, 분류기를 생성하고 [`.fit()`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier.fit) method를 이용해 훈련할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8095d201",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf = XGBClassifier(n_estimators=2, max_depth=1)\n",
    "\n",
    "xg_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba5b7a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061ebf2",
   "metadata": {},
   "source": [
    "다른 sklearn의 머신러닝 모형들과 비슷하게 [`.predict()`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier.predict)를 이용하여 클래스를 예측한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77057152-ba7c-41b3-a8c5-cc652592b429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8222db3-70af-429f-bd02-8e9baa20c7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 y값과의 비교\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd6445-c8b5-4c86-96c5-0aa8a7c2e677",
   "metadata": {},
   "source": [
    "[get_booster()](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier.get_booster)를 이용하면 훈련된 개별 트리들을 살펴볼 수 있다.\n",
    "\n",
    "각 트리를 그대로 출력하면, 인간이 알아볼 수 있는 형태는 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3865be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xgboost.core.Booster at 0x1a03010b820>,\n",
       " <xgboost.core.Booster at 0x1a03049bf40>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster = xg_clf.get_booster()\n",
    "# 개별 트리들의 feature 변수 이름을 원래 데이터의 feature_names를 이용하여 지정\n",
    "booster.feature_names = list(data.feature_names)\n",
    "individual_trees = list(booster)\n",
    "individual_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead19c78",
   "metadata": {},
   "source": [
    "XGBoost의 [`Booster`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster) 클래스는 XGBoost 라이브러리 내부에서 사용되는 독자적인 트리 혹은 트리 앙상블을 관리하는 구현체라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3c8d8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.core.Booster"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "486d63ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.core.Booster"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(individual_trees[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6816871-6621-4879-a4a1-47af9fe30640",
   "metadata": {},
   "source": [
    "위에서 생성한 [`booster`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster)의 메쏘드인 [`get_dump()`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster.get_dump)를 이용하면 트리들을 읽을 수 있는 문자열의 형태로 받아올 수 있다.\n",
    "\n",
    "훈련된 간단한 stump들이 2개 있음을 확인할 수 있으며, 분기 기준 및 leaf node들의 score들을 관찰할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c157c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_list = booster.get_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251c490c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\\n\\t1:leaf=-0.545454562\\n\\t2:leaf=0.0285714306\\n',\n",
       " '0:[petal width (cm)<1.75] yes=1,no=2,missing=1\\n\\t1:leaf=0.0412313528\\n\\t2:leaf=-0.513025463\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07817c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 0:\n",
      "0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\n",
      "\t1:leaf=-0.545454562\n",
      "\t2:leaf=0.0285714306\n",
      "\n",
      "\n",
      "Tree 1:\n",
      "0:[petal width (cm)<1.75] yes=1,no=2,missing=1\n",
      "\t1:leaf=0.0412313528\n",
      "\t2:leaf=-0.513025463\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(tree_list):\n",
    "    print(f\"Tree {i}:\\n{tree}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d3d75-5348-42ff-aeaf-982c95663857",
   "metadata": {},
   "source": [
    "혹은 [`trees_to_dataframe()`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster.trees_to_dataframe)을 이용한 다음의 방법으로 트리들을 관찰할 수 있다.\n",
    "\n",
    "* Gain 열의 값은 leaf 노드에 대해서는 score를 기록하고, non-leaf 노드에서는 노드 분할을 통해 얻는 score gain을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df5bdf68-c50d-4204-8eeb-9890d839ace2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>Node</th>\n",
       "      <th>ID</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Split</th>\n",
       "      <th>Yes</th>\n",
       "      <th>No</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Cover</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-2</td>\n",
       "      <td>0-1</td>\n",
       "      <td>26.102499</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1-0</td>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1-1</td>\n",
       "      <td>1-2</td>\n",
       "      <td>1-1</td>\n",
       "      <td>22.393280</td>\n",
       "      <td>29.287504</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>20.789238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1-2</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.513025</td>\n",
       "      <td>8.498266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tree  Node   ID            Feature  Split  Yes   No Missing       Gain   \n",
       "0     0     0  0-0  petal length (cm)   2.45  0-1  0-2     0-1  26.102499  \\\n",
       "1     0     1  0-1               Leaf    NaN  NaN  NaN     NaN  -0.545455   \n",
       "2     0     2  0-2               Leaf    NaN  NaN  NaN     NaN   0.028571   \n",
       "3     1     0  1-0   petal width (cm)   1.75  1-1  1-2     1-1  22.393280   \n",
       "4     1     1  1-1               Leaf    NaN  NaN  NaN     NaN   0.041231   \n",
       "5     1     2  1-2               Leaf    NaN  NaN  NaN     NaN  -0.513025   \n",
       "\n",
       "       Cover  Category  \n",
       "0  30.000000       NaN  \n",
       "1  10.000000       NaN  \n",
       "2  20.000000       NaN  \n",
       "3  29.287504       NaN  \n",
       "4  20.789238       NaN  \n",
       "5   8.498266       NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tree = booster.trees_to_dataframe()\n",
    "df_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f7258",
   "metadata": {},
   "source": [
    "각 weak learner들을 이용하여 예측을 할 수도 있다. `iteration_range`를 통해 시작과 끝을 정하여 예측에 사용할 트리들을 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e3b2e42-8365-4d99-bec5-821d72589ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 트리만을 이용\n",
    "xg_clf.predict(X_test, iteration_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5059f2ab-6a28-4b40-a9dc-327d73da83aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 트리만을 이용\n",
    "xg_clf.predict(X_test, iteration_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ac67f4-1348-47d5-99ba-5caab59d30cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 모델을 이용\n",
    "xg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7df9c1-f345-4df5-b377-6572bab8d20e",
   "metadata": {},
   "source": [
    "다음의 과정을 통해 leaf score에 따라 분류가 어떻게 이루어지는지 대략적으로 파악할 수 있다.\n",
    "\n",
    "먼저 [`apply()`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier.apply)를 이용하여 테스트 데이터가 각 트리에서 어떤 leaf에 떨어지는지 살펴보자.\n",
    "\n",
    "`apply()`는 X 값들을 인자로 받아, 각 값들이 어떤 leaf 노드로 떨어지는지 보여준다.\n",
    "\n",
    "결과의 각 열이 각 트리를 나타내고, 각 열의 숫자값이 leaf의 index를 나타낸다. 각 행은 각 데이터를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00203e2a-6111-43d1-b30f-e3bab672a7af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.],\n",
       "       [2., 1.],\n",
       "       [1., 1.],\n",
       "       [2., 1.],\n",
       "       [2., 1.],\n",
       "       [2., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_X_test = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "applied = xg_clf.apply(df_X_test)\n",
    "applied[:10, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2f8bb",
   "metadata": {},
   "source": [
    "지금의 예제에서는 부스팅에 사용한 트리가 2개 밖에 없으므로, 다음의 간단한 코드를 통해 test 데이터가 어떤 스코어를 가지는지 계산해 볼 수 있다.\n",
    "\n",
    "해당 스코어에 따라 어떤 클래스로 prediction이 이루어졌는지 살펴보자.\n",
    "\n",
    "양의 score는 1로 예측되고, 음의 score는 0으로 예측된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "913cd649-5002-4b75-8cba-31b2e80d3128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.504223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.484454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction     score\n",
       "0            0 -0.484454\n",
       "1            0 -0.484454\n",
       "2            1  0.069803\n",
       "3            0 -0.504223\n",
       "4            1  0.069803\n",
       "5            1  0.069803\n",
       "6            1  0.069803\n",
       "7            0 -0.504223\n",
       "8            0 -0.504223\n",
       "9            0 -0.484454\n",
       "10           0 -0.484454\n",
       "11           0 -0.484454\n",
       "12           1  0.069803\n",
       "13           1  0.069803\n",
       "14           0 -0.504223\n",
       "15           0 -0.484454\n",
       "16           1  0.069803\n",
       "17           0 -0.484454\n",
       "18           0 -0.504223\n",
       "19           0 -0.484454\n",
       "20           1  0.069803\n",
       "21           0 -0.484454\n",
       "22           0 -0.504223\n",
       "23           0 -0.484454\n",
       "24           0 -0.504223\n",
       "25           0 -0.504223\n",
       "26           0 -0.504223\n",
       "27           0 -0.484454\n",
       "28           0 -0.504223\n",
       "29           0 -0.484454"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = []\n",
    "for i in range(0, X_test.shape[0]): #\n",
    "    s1 = df_tree[df_tree[\"ID\"] == \"0-\" + str(int(applied[i, 0]))]  # 첫번째 트리의 해당 노드에서 score 가져오기\n",
    "    s2 = df_tree[df_tree[\"ID\"] == \"1-\" + str(int(applied[i, 1]))]  # 두번째 트리의 해당 노드에서 score 가져오기\n",
    "    score_list.append(s1.iloc[0][\"Gain\"] + s2.iloc[0][\"Gain\"])   # 각 트리의 leaf 노드 가중치들의 합\n",
    "\n",
    "pd.DataFrame({\"prediction\": xg_clf.predict(X_test), \"score\": score_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68e8ff-0440-4764-9279-474f373f9701",
   "metadata": {},
   "source": [
    "이번에는 Weak learner들의 max depth를 2로 늘리고, boosting 횟수를 3으로 늘렸다.\n",
    "\n",
    "부스팅 단계에서 트리가 완전히 2번 분할되기도 하고 그렇지 않기도 함을 관찰할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76b09386-f689-4e7d-817c-ab5c834330d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 0:\n",
      "0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\n",
      "\t1:leaf=-0.545454562\n",
      "\t2:[petal length (cm)<4.75] yes=3,no=4,missing=3\n",
      "\t\t3:leaf=0.514285743\n",
      "\t\t4:leaf=-0.41739133\n",
      "\n",
      "\n",
      "Tree 1:\n",
      "0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\n",
      "\t1:leaf=-0.427828759\n",
      "\t2:[petal width (cm)<1.75] yes=3,no=4,missing=3\n",
      "\t\t3:leaf=0.356582165\n",
      "\t\t4:leaf=-0.410363704\n",
      "\n",
      "\n",
      "Tree 2:\n",
      "0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\n",
      "\t1:leaf=-0.367224514\n",
      "\t2:[petal length (cm)<4.94999981] yes=3,no=4,missing=3\n",
      "\t\t3:leaf=0.30028519\n",
      "\t\t4:leaf=-0.36476928\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_clf2 = XGBClassifier(n_estimators=3, max_depth=2)\n",
    "xg_clf2.fit(X_train, y_train)\n",
    "booster2 = xg_clf2.get_booster()\n",
    "booster2.feature_names = list(data.feature_names)\n",
    "\n",
    "tree_list2 = booster2.get_dump()\n",
    "for i, tree in enumerate(tree_list2):\n",
    "    print(f\"Tree {i}:\\n{tree}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43d4473b-96f5-41d7-938b-0e7695834b77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>Node</th>\n",
       "      <th>ID</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Split</th>\n",
       "      <th>Yes</th>\n",
       "      <th>No</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Cover</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-2</td>\n",
       "      <td>0-1</td>\n",
       "      <td>26.102499</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0-3</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0-3</td>\n",
       "      <td>52.927536</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0-3</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.417391</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1-0</td>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1-1</td>\n",
       "      <td>1-2</td>\n",
       "      <td>1-1</td>\n",
       "      <td>15.147726</td>\n",
       "      <td>28.245752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.427829</td>\n",
       "      <td>9.291584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1-2</td>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1-3</td>\n",
       "      <td>1-4</td>\n",
       "      <td>1-3</td>\n",
       "      <td>33.674084</td>\n",
       "      <td>18.954166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1-3</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.356582</td>\n",
       "      <td>10.813885</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1-4</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.410364</td>\n",
       "      <td>8.140282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2-0</td>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2-1</td>\n",
       "      <td>2-2</td>\n",
       "      <td>2-1</td>\n",
       "      <td>9.663538</td>\n",
       "      <td>25.058861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2-1</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.367225</td>\n",
       "      <td>7.961054</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2-2</td>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2-3</td>\n",
       "      <td>2-4</td>\n",
       "      <td>2-3</td>\n",
       "      <td>22.974699</td>\n",
       "      <td>17.097807</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2-3</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300285</td>\n",
       "      <td>9.923292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2-4</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.364769</td>\n",
       "      <td>7.174514</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tree  Node   ID            Feature  Split  Yes   No Missing       Gain   \n",
       "0      0     0  0-0  petal length (cm)   2.45  0-1  0-2     0-1  26.102499  \\\n",
       "1      0     1  0-1               Leaf    NaN  NaN  NaN     NaN  -0.545455   \n",
       "2      0     2  0-2  petal length (cm)   4.75  0-3  0-4     0-3  52.927536   \n",
       "3      0     3  0-3               Leaf    NaN  NaN  NaN     NaN   0.514286   \n",
       "4      0     4  0-4               Leaf    NaN  NaN  NaN     NaN  -0.417391   \n",
       "5      1     0  1-0  petal length (cm)   2.45  1-1  1-2     1-1  15.147726   \n",
       "6      1     1  1-1               Leaf    NaN  NaN  NaN     NaN  -0.427829   \n",
       "7      1     2  1-2   petal width (cm)   1.75  1-3  1-4     1-3  33.674084   \n",
       "8      1     3  1-3               Leaf    NaN  NaN  NaN     NaN   0.356582   \n",
       "9      1     4  1-4               Leaf    NaN  NaN  NaN     NaN  -0.410364   \n",
       "10     2     0  2-0  petal length (cm)   2.45  2-1  2-2     2-1   9.663538   \n",
       "11     2     1  2-1               Leaf    NaN  NaN  NaN     NaN  -0.367225   \n",
       "12     2     2  2-2  petal length (cm)   4.95  2-3  2-4     2-3  22.974699   \n",
       "13     2     3  2-3               Leaf    NaN  NaN  NaN     NaN   0.300285   \n",
       "14     2     4  2-4               Leaf    NaN  NaN  NaN     NaN  -0.364769   \n",
       "\n",
       "        Cover  Category  \n",
       "0   30.000000       NaN  \n",
       "1   10.000000       NaN  \n",
       "2   20.000000       NaN  \n",
       "3    9.500000       NaN  \n",
       "4   10.500000       NaN  \n",
       "5   28.245752       NaN  \n",
       "6    9.291584       NaN  \n",
       "7   18.954166       NaN  \n",
       "8   10.813885       NaN  \n",
       "9    8.140282       NaN  \n",
       "10  25.058861       NaN  \n",
       "11   7.961054       NaN  \n",
       "12  17.097807       NaN  \n",
       "13   9.923292       NaN  \n",
       "14   7.174514       NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tree2 = booster2.trees_to_dataframe()\n",
    "df_tree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22dcb3f0-226d-4b90-90bc-f2c91d8c0964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 4.],\n",
       "       [4., 4., 4.],\n",
       "       [3., 3., 3.],\n",
       "       [1., 1., 1.],\n",
       "       [3., 3., 3.],\n",
       "       [3., 3., 3.],\n",
       "       [3., 3., 3.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [4., 4., 4.],\n",
       "       [4., 4., 4.],\n",
       "       [4., 4., 4.],\n",
       "       [3., 3., 3.],\n",
       "       [3., 3., 3.],\n",
       "       [1., 1., 1.],\n",
       "       [4., 4., 4.],\n",
       "       [3., 3., 3.],\n",
       "       [4., 4., 4.],\n",
       "       [1., 1., 1.],\n",
       "       [4., 4., 4.],\n",
       "       [4., 3., 4.],\n",
       "       [4., 4., 4.],\n",
       "       [1., 1., 1.],\n",
       "       [4., 4., 4.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [4., 4., 4.],\n",
       "       [1., 1., 1.],\n",
       "       [4., 4., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "applied2 = xg_clf2.apply(df_X_test)\n",
    "applied2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27f3c7",
   "metadata": {},
   "source": [
    "이번에는 트리가 3개이기 때문에, `for`문 내에서 스코어를 3번 추출하여 계산한다. \n",
    "\n",
    "어떤 테스트 데이터에 대한 총 score는 각 트리의 leaf 노드에서 추출한 score들의 합이다.\n",
    "\n",
    "마찬가지로 score에 따라 최종 prediction이 어떻게 이루어졌는지 관찰하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6959a6",
   "metadata": {},
   "source": [
    "이전에 공부한 것처럼 score값들은 sigmoid 함수를 이용하여 확률값으로 변환할 수 있다.\n",
    "\n",
    "이것은 [`predict_prob`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier.predict_proba)에서 계산한 값과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07aec593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b8df3a1-398b-4476-8a8d-5e7c8cfc850f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>prob_by_score</th>\n",
       "      <th>P(Y=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1.171153</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.763353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.425578</td>\n",
       "      <td>0.395183</td>\n",
       "      <td>0.395183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.192524</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>0.232808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction     score  prob_by_score    P(Y=1)\n",
       "0            0 -1.192524       0.232808  0.232808\n",
       "1            0 -1.192524       0.232808  0.232808\n",
       "2            1  1.171153       0.763353  0.763353\n",
       "3            0 -1.340508       0.207427  0.207427\n",
       "4            1  1.171153       0.763353  0.763353\n",
       "5            1  1.171153       0.763353  0.763353\n",
       "6            1  1.171153       0.763353  0.763353\n",
       "7            0 -1.340508       0.207427  0.207427\n",
       "8            0 -1.340508       0.207427  0.207427\n",
       "9            0 -1.192524       0.232808  0.232808\n",
       "10           0 -1.192524       0.232808  0.232808\n",
       "11           0 -1.192524       0.232808  0.232808\n",
       "12           1  1.171153       0.763353  0.763353\n",
       "13           1  1.171153       0.763353  0.763353\n",
       "14           0 -1.340508       0.207427  0.207427\n",
       "15           0 -1.192524       0.232808  0.232808\n",
       "16           1  1.171153       0.763353  0.763353\n",
       "17           0 -1.192524       0.232808  0.232808\n",
       "18           0 -1.340508       0.207427  0.207427\n",
       "19           0 -1.192524       0.232808  0.232808\n",
       "20           0 -0.425578       0.395183  0.395183\n",
       "21           0 -1.192524       0.232808  0.232808\n",
       "22           0 -1.340508       0.207427  0.207427\n",
       "23           0 -1.192524       0.232808  0.232808\n",
       "24           0 -1.340508       0.207427  0.207427\n",
       "25           0 -1.340508       0.207427  0.207427\n",
       "26           0 -1.340508       0.207427  0.207427\n",
       "27           0 -1.192524       0.232808  0.232808\n",
       "28           0 -1.340508       0.207427  0.207427\n",
       "29           0 -1.192524       0.232808  0.232808"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list2 = []\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    total_score = 0\n",
    "    for j in range(xg_clf2.n_estimators):\n",
    "        selected_raw = df_tree2[df_tree2[\"ID\"] == f\"{j}-\" + str(int(applied2[i, j]))]\n",
    "        total_score += selected_raw.iloc[0][\"Gain\"]\n",
    "    \n",
    "    score_list2.append(total_score)\n",
    "\n",
    "prob = 1/(1 + np.exp(-np.array(score_list2)))\n",
    "pd.DataFrame({\"prediction\": xg_clf2.predict(X_test), \"score\": score_list2, \"prob_by_score\" : prob, \"P(Y=1)\" : xg_clf2.predict_proba(X_test)[:,1].reshape(-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcecbdd",
   "metadata": {},
   "source": [
    "마지막으로 하이퍼파라미터들을 따로 셋팅하지 않고, xgboost를 진행해 본다.\n",
    "\n",
    "xgboost의 파라미터 기본 셋팅은 다음 링크를 참조한다.\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "예를 들어, `max_depth`의 기본값은 6이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b4fd065",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf_d = XGBClassifier()\n",
    "xg_clf_d.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c15bb234-b61f-4289-abfa-7cd5850dff0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>real _value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction  real _value\n",
       "0            0            0\n",
       "1            0            0\n",
       "2            1            1\n",
       "3            0            0\n",
       "4            1            1\n",
       "5            1            1\n",
       "6            1            1\n",
       "7            0            0\n",
       "8            0            0\n",
       "9            0            0\n",
       "10           0            0\n",
       "11           0            0\n",
       "12           1            1\n",
       "13           1            1\n",
       "14           0            0\n",
       "15           0            0\n",
       "16           1            1\n",
       "17           0            0\n",
       "18           0            0\n",
       "19           0            0\n",
       "20           0            1\n",
       "21           0            0\n",
       "22           0            0\n",
       "23           0            0\n",
       "24           0            0\n",
       "25           0            0\n",
       "26           0            0\n",
       "27           0            0\n",
       "28           0            0\n",
       "29           0            0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"prediction\" : xg_clf_d.predict(X_test), \"real _value\" :y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84f2f18e-8f65-4e5c-9345-d7eca3e314fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#상당히 많은 트리들을 볼 수 있다.\n",
    "\n",
    "boosters = xg_clf_d.get_booster()\n",
    "boosters.feature_names = list(data.feature_names)\n",
    "\n",
    "tree_list = boosters.get_dump()\n",
    "\n",
    "len(tree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d0ff88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\n",
      "\t1:leaf=-0.545454562\n",
      "\t2:[petal length (cm)<4.75] yes=3,no=4,missing=3\n",
      "\t\t3:[sepal length (cm)<5.05000019] yes=5,no=6,missing=5\n",
      "\t\t\t5:leaf=0.150000006\n",
      "\t\t\t6:leaf=0.536842108\n",
      "\t\t4:[petal width (cm)<1.75] yes=7,no=8,missing=7\n",
      "\t\t\t7:[sepal length (cm)<6.5] yes=9,no=10,missing=9\n",
      "\t\t\t\t9:leaf=-0.150000006\n",
      "\t\t\t\t10:leaf=0.150000006\n",
      "\t\t\t8:leaf=-0.505263209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52de868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[petal length (cm)<2.45000005] yes=1,no=2,missing=1\n",
      "\t1:leaf=-0.427828759\n",
      "\t2:[petal length (cm)<4.85000038] yes=3,no=4,missing=3\n",
      "\t\t3:[petal width (cm)<1.54999995] yes=5,no=6,missing=5\n",
      "\t\t\t5:leaf=0.43376565\n",
      "\t\t\t6:leaf=0.00886989571\n",
      "\t\t4:[petal width (cm)<1.75] yes=7,no=8,missing=7\n",
      "\t\t\t7:leaf=-0.0506427959\n",
      "\t\t\t8:leaf=-0.422881484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cc0cfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>prob_by_score</th>\n",
       "      <th>P(Y=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.758293</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.008507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.037132</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.982658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.185158</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>0.994432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4.425025</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>0.988168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4.675765</td>\n",
       "      <td>0.990768</td>\n",
       "      <td>0.990768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.377121</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>0.012406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.758293</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.008507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>4.536603</td>\n",
       "      <td>0.989404</td>\n",
       "      <td>0.989404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>4.038764</td>\n",
       "      <td>0.982686</td>\n",
       "      <td>0.982686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>4.760330</td>\n",
       "      <td>0.991510</td>\n",
       "      <td>0.991510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.592437</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.010027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.492708</td>\n",
       "      <td>0.029520</td>\n",
       "      <td>0.029520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.682799</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.009168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.955665</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.049469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.576082</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction     score  prob_by_score    P(Y=1)\n",
       "0            0 -4.758293       0.008507  0.008507\n",
       "1            0 -4.576082       0.010190  0.010190\n",
       "2            1  4.037132       0.982658  0.982658\n",
       "3            0 -4.682799       0.009168  0.009168\n",
       "4            1  5.185158       0.994432  0.994432\n",
       "5            1  4.425025       0.988168  0.988168\n",
       "6            1  4.675765       0.990768  0.990768\n",
       "7            0 -4.682799       0.009168  0.009168\n",
       "8            0 -4.377121       0.012406  0.012406\n",
       "9            0 -4.758293       0.008507  0.008507\n",
       "10           0 -4.576082       0.010190  0.010190\n",
       "11           0 -4.576082       0.010190  0.010190\n",
       "12           1  4.536603       0.989404  0.989404\n",
       "13           1  4.038764       0.982686  0.982686\n",
       "14           0 -4.682799       0.009168  0.009168\n",
       "15           0 -4.576082       0.010190  0.010190\n",
       "16           1  4.760330       0.991510  0.991510\n",
       "17           0 -4.576082       0.010190  0.010190\n",
       "18           0 -4.592437       0.010027  0.010027\n",
       "19           0 -4.576082       0.010190  0.010190\n",
       "20           0 -3.492708       0.029520  0.029520\n",
       "21           0 -4.576082       0.010190  0.010190\n",
       "22           0 -4.682799       0.009168  0.009168\n",
       "23           0 -4.576082       0.010190  0.010190\n",
       "24           0 -4.682799       0.009168  0.009168\n",
       "25           0 -4.682799       0.009168  0.009168\n",
       "26           0 -4.682799       0.009168  0.009168\n",
       "27           0 -4.576082       0.010190  0.010190\n",
       "28           0 -2.955665       0.049469  0.049469\n",
       "29           0 -4.576082       0.010190  0.010190"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tree_d = xg_clf_d.get_booster().trees_to_dataframe()\n",
    "applied_d = xg_clf_d.apply(df_X_test)\n",
    "score_list_d = []\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    total_score = 0\n",
    "    for j in range(xg_clf_d.n_estimators):\n",
    "        selected_raw = df_tree_d[df_tree_d[\"ID\"] == f\"{j}-\" + str(int(applied_d[i, j]))]\n",
    "        total_score += selected_raw.iloc[0][\"Gain\"]\n",
    "    \n",
    "    score_list_d.append(total_score)\n",
    "    \n",
    "\n",
    "prob = 1/(1 + np.exp(-np.array(score_list_d)))\n",
    "pd.DataFrame({\"prediction\": xg_clf_d.predict(X_test), \"score\": score_list_d, \"prob_by_score\" : prob, \\\n",
    "              \"P(Y=1)\" : xg_clf_d.predict_proba(X_test)[:,1].reshape(-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037d7a5-d964-4d5c-9906-64ef69e7d266",
   "metadata": {},
   "source": [
    "### 예제 : `make_hastie_10_2` \n",
    "\n",
    "[`make_hastie_10_2`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_hastie_10_2.html)데이터 를 이용하여 XGBoost와 일반 gradient boosting의 속도를 비교해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c5e61c3-9607-45a3-8602-263b03140ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_hastie_10_2(n_samples=12_000, random_state=1)\n",
    "\n",
    "y[y == -1] = 0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=2_000, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bb78528-ddd9-4008-bec7-70e9b10ba0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators = 400, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "505557f4-04a8-4a0c-a336-b14a481dca4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 ms ± 16.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1522aa08-dfed-4fa7-bded-9c58fccaf5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9485"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7551f15c-643c-4fa7-b1c7-a67ef30a66d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "n_estimators = 400\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7505296-5acb-4ad3-b676-fa24e1a47e47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.87 s ± 506 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gb_clf .fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03cc212e-0723-4853-83eb-7c764e5b3524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f2538-832d-4ca8-8c3e-474ec6e5179f",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터\n",
    "\n",
    "심장병 판별 자료 예제를 이용하여 XGBoost에서 하이퍼 파라미터를 어떻게 설정하는지 간단히 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed28fcfa-e387-4668-8b6d-f063e1c175e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope   \n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0  \\\n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/rickiepark/handson-gb/main/Chapter02/heart_disease.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97dea76c-572b-40fa-9256-9fcfd38db7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1ead09f-5849-44a9-8c31-7b699276cfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "675f0519-21ce-45ac-bb55-a36e33b5d86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04518f3",
   "metadata": {},
   "source": [
    "아래 코드에서 `booster = \"gbtree\", objective = \"binary:logistic\"`는 사실 `XGBClassifier`의 default 값들이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c05df3f6-da9d-4d5f-b6c1-b2b93be63258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(booster = \"gbtree\", objective = \"binary:logistic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70f02b",
   "metadata": {},
   "source": [
    "위 모델을 이용하여 5-fold cross validation 에러를 계산해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5cbf194e-dea1-403c-862a-b90c97b330cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149726775956283"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178202f-7cf9-4099-930a-f119910e8273",
   "metadata": {},
   "source": [
    "한편, [`sklearn.model_selection.StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)는 $y$의 클래스의 비율을 일정하게 하여 k-fold cross-validation을 하게 하므로, 더 정확한 테스트 에러 추정치를 얻을 수 있다고 알려져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "52e94d19-1e49-4cdf-8c1a-6f4494ae3883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c24e3320-ff51-4a42-85ef-093c8e811dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149726775956283"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e952e6-1d4a-4e5e-b489-a89477a94579",
   "metadata": {},
   "source": [
    "하이퍼파라미터 튜닝은 기본적으로 [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 나 [`sklearn.model_selection.RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)을 이용한다.\n",
    "\n",
    "`sklearn.model_selection.GridSearchCV`는 하이퍼 파라미터들이 가질 수 있는 여러 값들을 그리드 형태로 지정하여 모두 테스트 하는 방식이다.\n",
    "\n",
    "`param_grid`는 탐색할 파라미터 값들의 리스트를 나타내며, 파라미터 이름을 key로 삼아 dictionary로 표현된다.\n",
    "\n",
    "비슷하게 `sklearn.model_selection.RandomizedSearchCV`는 탐색할 파라미터가 램덤하게 샘플링될 분포를 `param_distributions`로 제공해 주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed744023-1405-4714-9849-7a9df4f8d7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e967b5c",
   "metadata": {},
   "source": [
    "많은 하이퍼 파라미터들에 대해 비슷한 작업을 수행할 것이므로, 함수로 만들어 사용해 보자.\n",
    "\n",
    "`random`이 `False`일 경우 grid search를, `True`일 경우 Randomized search를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0256a57a-4509-49fd-ae2d-1b6c7af6810c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grid_search(params, random=False): \n",
    "\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', verbosity=0)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(estimator = xgb, param_distributions = params, cv=kfold, n_iter=20, \n",
    "                                  n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(estimator = xgb, param_grid = params, cv=kfold, n_jobs=-1)\n",
    "    \n",
    "    grid.fit(X, y)\n",
    "\n",
    "    best_params = grid.best_params_\n",
    "    print(\"최상의 매개변수:\", best_params) \n",
    "    best_score = grid.best_score_\n",
    "    print(\"최상의 점수: {:.5f}\".format(best_score))\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5421174a-1a3f-4517-a4d9-0b6c37edc3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 100}\n",
      "최상의 점수: 0.82164\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'n_estimators':[100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c530624e-5b34-46db-8c14-265cf7693833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'learning_rate': 0.05}\n",
      "최상의 점수: 0.81514\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5836540-b5d7-4eb9-9968-0e91c7f1e3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'max_depth': 8}\n",
      "최상의 점수: 0.81847\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08717359-5559-4966-9abd-cb52f2f56d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'gamma': 0.1}\n",
      "최상의 점수: 0.83158\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'gamma':[0, 0.01, 0.1, 0.5, 1, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3907e27b-6f2b-41d1-a159-480fbb8dd3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_child_weight': 5}\n",
      "최상의 점수: 0.80525\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'min_child_weight':[1, 2, 3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d3f0729-5ea7-4a5a-97cd-9b0671fd6b49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'subsample': 0.7}\n",
      "최상의 점수: 0.80514\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'subsample':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96ec3aab-4fcc-474b-9e6c-c8eb6c026ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'colsample_bytree': 0.7}\n",
      "최상의 점수: 0.82158\n"
     ]
    }
   ],
   "source": [
    "_ = grid_search(params={'colsample_bytree':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe88462",
   "metadata": {},
   "source": [
    "탐색의 대상이 너무 많을 때는 randomized search를 사용하는 것도 좋은 방법이다.\n",
    "\n",
    "다음의 parameter 조합은 너무 많기 때문에, random search를 이용했다.\n",
    "\n",
    "주어진 parameter 조합 중의 일부를 랜덤하게 선택하여 에러를 측정하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d922522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'subsample': 0.7, 'n_estimators': 25, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.2}\n",
      "최상의 점수: 0.84153\n"
     ]
    }
   ],
   "source": [
    "grid = grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                    'max_depth':[1, 2, 3, 4, 5, None], \n",
    "                    'n_estimators':[2, 25, 50, 75, 100]}, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9ce534e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'n_estimators': 25,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 1,\n",
       " 'learning_rate': 0.2}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47dfa4b",
   "metadata": {},
   "source": [
    "`best_estimator_`는 최적의 하이퍼파라미터 조합으로 학습된 모델 객체이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "532fb768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd0e704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_op = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "24353606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_op.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bc70b",
   "metadata": {},
   "source": [
    "[`feature_importnaces_`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier.feature_importances_)는 XGBoost 모델에서 각 피처(변수)의 중요도를 나타내는 속성이다. \n",
    "\n",
    "중요도는 해당 피처가 모델의 예측에 얼마나 큰 영향을 미치는지를 나타내는 값으로 해석된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8076149c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.09480923, 0.18959753, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.14991102, 0.09621289, 0.0931586 ,\n",
       "       0.05830555, 0.12986076, 0.18814443], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_op.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7dda3d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: cp, Importance: 0.18959753215312958\n",
      "Feature: thal, Importance: 0.18814443051815033\n",
      "Feature: thalach, Importance: 0.14991101622581482\n",
      "Feature: ca, Importance: 0.1298607587814331\n",
      "Feature: exang, Importance: 0.09621288627386093\n",
      "Feature: sex, Importance: 0.09480923414230347\n",
      "Feature: oldpeak, Importance: 0.09315860271453857\n",
      "Feature: slope, Importance: 0.05830554664134979\n",
      "Feature: restecg, Importance: 0.0\n",
      "Feature: fbs, Importance: 0.0\n",
      "Feature: chol, Importance: 0.0\n",
      "Feature: trestbps, Importance: 0.0\n",
      "Feature: age, Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_op.feature_importances_\n",
    "\n",
    "# 중요도를 기준으로 내림차순 정렬하여 feature 이름과 중요도를 출력\n",
    "sorted_indices = importances.argsort()[::-1]  # 중요도를 기준으로 내림차순 정렬된 인덱스\n",
    "sorted_importances = importances[sorted_indices]\n",
    "sorted_feature_names = X.columns[sorted_indices]\n",
    "\n",
    "for feature_name, importance in zip(sorted_feature_names, sorted_importances):\n",
    "    print(f\"Feature: {feature_name}, Importance: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dae59a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "_ = plot_importance(xgb_op, importance_type='gain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
